# Exercice 7: Consommateur Kafka vers HDFS

## ğŸ—„ï¸ Objectif
CrÃ©er un consommateur Kafka qui lit les donnÃ©es mÃ©tÃ©o et les organise dans une structure HDFS hiÃ©rarchique par pays et ville.

## ğŸ—ï¸ Architecture
```
hdfs_consumer.py
â”œâ”€â”€ HDFSWeatherConsumer
â”‚   â”œâ”€â”€ _extract_location_info() â†’ Extraction pays/ville des messages
â”‚   â”œâ”€â”€ _get_hdfs_path() â†’ GÃ©nÃ©ration chemins HDFS structurÃ©s
â”‚   â”œâ”€â”€ _append_to_hdfs_file() â†’ Sauvegarde JSON Lines
â”‚   â””â”€â”€ start_consuming() â†’ Boucle de consommation Kafka
â””â”€â”€ Structure HDFS â†’ /hdfs-data/{country}/{city}/alerts.json
```

## ğŸ“ Structure HDFS GÃ©nÃ©rÃ©e
```
hdfs-data/
â”œâ”€â”€ FR/
â”‚   â””â”€â”€ Paris/
â”‚       â””â”€â”€ alerts.json
â”œâ”€â”€ JP/
â”‚   â””â”€â”€ Tokyo/
â”‚       â””â”€â”€ alerts.json
â”œâ”€â”€ US/
â”‚   â””â”€â”€ New_York/
â”‚       â””â”€â”€ alerts.json
â””â”€â”€ UNKNOWN/
    â””â”€â”€ fallback_cities/
        â””â”€â”€ alerts.json
```

## ğŸ”§ Installation

### PrÃ©requis
- Apache Kafka en cours d'exÃ©cution
- Topics avec donnÃ©es mÃ©tÃ©o gÃ©olocalisÃ©es
- Python 3.7+
- AccÃ¨s en Ã©criture au systÃ¨me de fichiers

### DÃ©pendances
```bash
pip install -r requirements.txt
```

## ğŸš€ Utilisation

### DÃ©marrage rapide
```bash
# Lancer le test complet avec gÃ©nÃ©ration de donnÃ©es
.\test-hdfs.ps1

# Ou manuellement:
python hdfs_consumer.py --hdfs-path ./hdfs-data
```

### Options avancÃ©es
```bash
# Topics spÃ©cifiques
python hdfs_consumer.py --topics geo_weather_stream --hdfs-path ./my-hdfs

# Serveur Kafka personnalisÃ©
python hdfs_consumer.py --server my-kafka:9092 --hdfs-path /hdfs/weather
```

## ğŸ“Š Format des DonnÃ©es

### Topics consommÃ©s
- **geo_weather_stream**: DonnÃ©es enrichies avec gÃ©olocalisation
- **weather_transformed**: DonnÃ©es transformÃ©es avec alertes
- Compatible avec tous les topics des exercices prÃ©cÃ©dents

### Format de sauvegarde (JSON Lines)
```json
{
  "location": {
    "city": "Paris",
    "country": "France",
    "country_code": "FR",
    "latitude": 48.8566,
    "longitude": 2.3522
  },
  "weather": {
    "temperature": 15.2,
    "windspeed": 12.5,
    "weathercode": 3
  },
  "hdfs_metadata": {
    "processed_at": "2024-01-15T14:30:00Z",
    "consumer_id": "hdfs-weather-consumer",
    "file_path": "./hdfs-data/FR/Paris/alerts.json"
  }
}
```

## ğŸ”„ Gestion des DonnÃ©es

### Extraction de localisation
1. **geo_weather_stream**: Utilise `location.country_code` et `location.city`
2. **weather_transformed**: DÃ©duit depuis `location_data` ou coordonnÃ©es
3. **Fallback**: GÃ©nÃ¨re codes depuis latitude/longitude
4. **DÃ©faut**: Place dans `UNKNOWN/UNKNOWN` si pas de gÃ©olocalisation

### Organisation HDFS
- **Partitioning gÃ©ographique**: Un rÃ©pertoire par pays
- **Sous-partitioning**: Un rÃ©pertoire par ville
- **Fichier unique**: `alerts.json` en format JSON Lines
- **MÃ©tadonnÃ©es**: Timestamp et informations de traitement

## ğŸ› ï¸ FonctionnalitÃ©s

### Robustesse
- **Signal handling**: ArrÃªt propre avec Ctrl+C
- **Gestion d'erreurs**: Retry automatique et logging
- **Consumer groups**: Ã‰vite la duplication de messages
- **Auto-commit**: Sauvegarde automatique des offsets

### Performance
- **Polling efficace**: Batch processing des messages
- **CrÃ©ation lazy**: RÃ©pertoires crÃ©Ã©s Ã  la demande
- **JSON Lines**: Format optimisÃ© pour l'append
- **Statistiques**: Suivi en temps rÃ©el du traitement

### Monitoring
- **Compteurs**: Messages traitÃ©s, erreurs, pays/villes
- **Affichage pÃ©riodique**: ProgrÃ¨s toutes les 10 messages
- **Structure finale**: Visualisation HDFS Ã  l'arrÃªt
- **Logging dÃ©taillÃ©**: Debug et troubleshooting

## ğŸ§ª Tests

### Validation complÃ¨te
```bash
# Test avec gÃ©nÃ©ration automatique de donnÃ©es
.\test-hdfs.ps1
```

### VÃ©rification manuelle
```bash
# Lancer le consommateur
python hdfs_consumer.py

# Dans un autre terminal, gÃ©nÃ©rer des donnÃ©es
python ..\exercice6\geo_weather.py "London" "UK" --topic geo_weather_stream --count 5

# VÃ©rifier la structure crÃ©Ã©e
ls -R hdfs-data/
```

## ğŸ“ˆ IntÃ©gration Pipeline

### CompatibilitÃ© upstream
- **Exercice 3**: current_weather.py â†’ weather_stream
- **Exercice 4**: weather_alerts.py â†’ weather_transformed  
- **Exercice 5**: weather_aggregates.py â†’ weather_aggregates
- **Exercice 6**: geo_weather.py â†’ geo_weather_stream

### PrÃ©paration downstream
- **Exercice 8**: Fichiers HDFS prÃªts pour visualisation
- **Analytics**: Structure optimisÃ©e pour requÃªtes gÃ©ographiques
- **Backup**: Persistence des donnÃ©es mÃ©tÃ©o historiques

## ğŸ“‹ MÃ©triques

### Performance typique
- **Throughput**: ~100 messages/sec pour donnÃ©es mÃ©tÃ©o
- **Latence**: <10ms par message (I/O local)
- **Stockage**: ~1KB par message mÃ©tÃ©o enrichi
- **ScalabilitÃ©**: LimitÃ© par I/O disque local

### Ressources
- **RAM**: ~50MB base + cache messages
- **Disque**: Croissance linÃ©aire avec les donnÃ©es
- **CPU**: Minimal, principalement I/O bound
- **RÃ©seau**: Consommation Kafka standard

## ğŸ”„ Extensions Futures
- [ ] Support HDFS rÃ©el (hdfs3, pydoop)
- [ ] Compression des fichiers JSON (gzip)
- [ ] Partitioning temporel (par jour/heure)
- [ ] Rotation automatique des fichiers
- [ ] MÃ©triques Prometheus/Grafana
- [ ] Mode batch pour historical data