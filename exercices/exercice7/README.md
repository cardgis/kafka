# ğŸ“ Exercice 7: Consumer HDFS et Stockage DistribuÃ©

## ğŸ¯ Objectif
CrÃ©er un consumer Kafka avancÃ© qui stocke les donnÃ©es mÃ©tÃ©orologiques dans une structure HDFS (Hadoop Distributed File System) organisÃ©e par pays et ville pour faciliter les analyses ultÃ©rieures.

## ğŸ“‹ SpÃ©cifications

### **Architecture HDFS**
```
hdfs-data/
â”œâ”€â”€ FR/
â”‚   â”œâ”€â”€ Paris/
â”‚   â”‚   â””â”€â”€ alerts.json
â”‚   â””â”€â”€ Lyon/
â”‚       â””â”€â”€ alerts.json
â”œâ”€â”€ DE/
â”‚   â”œâ”€â”€ Berlin/
â”‚   â”‚   â””â”€â”€ alerts.json
â”‚   â””â”€â”€ Munich/
â”‚       â””â”€â”€ alerts.json
â”œâ”€â”€ US/
â”‚   â”œâ”€â”€ New-York/
â”‚   â”‚   â””â”€â”€ alerts.json
â”‚   â””â”€â”€ Los-Angeles/
â”‚       â””â”€â”€ alerts.json
â””â”€â”€ UNKNOWN/
    â””â”€â”€ Unknown-City/
        â””â”€â”€ alerts.json
```

### **FonctionnalitÃ©s ClÃ©s**
1. **Consumer Multi-Topics**: Lecture simultanÃ©e de plusieurs topics Kafka
2. **Partitioning GÃ©ographique**: Organisation automatique par pays/ville
3. **Format JSONL**: Stockage en JSON Lines pour performance
4. **Traitement Batch**: Ã‰criture par lots pour optimiser les I/O
5. **Gestion d'Erreurs**: Robustesse et rÃ©cupÃ©ration automatique
6. **Monitoring**: MÃ©triques de performance et logs dÃ©taillÃ©s

## ğŸš€ Utilisation

### **Consumer Standard**
```bash
python hdfs_consumer.py --hdfs-path "./hdfs-data" --topics geo_weather_stream
```

### **Consumer Multi-Topics**
```bash
python hdfs_consumer.py --hdfs-path "./hdfs-data" --topics "weather_stream,geo_weather_stream,alert_stream"
```

### **Mode Monitoring**
```bash
python hdfs_consumer.py --hdfs-path "./hdfs-data" --topics geo_weather_stream --monitoring
```

### **Configuration AvancÃ©e**
```bash
python hdfs_consumer.py \
  --hdfs-path "./hdfs-data" \
  --topics "geo_weather_stream" \
  --batch-size 100 \
  --flush-interval 30 \
  --monitoring
```

## ğŸ› ï¸ Architecture Technique

### **Pipeline de Traitement**
1. **Kafka Consumer**: Connexion aux topics avec auto-commit
2. **Data Parsing**: Validation et parsing JSON des messages
3. **Geographic Extraction**: Extraction pays/ville des donnÃ©es
4. **Path Resolution**: CrÃ©ation dynamique des chemins HDFS
5. **Batch Processing**: Accumulation des donnÃ©es par lot
6. **HDFS Write**: Ã‰criture optimisÃ©e en format JSONL

### **Structure des DonnÃ©es**
```json
{
  "timestamp": "2025-09-22T14:30:00Z",
  "city": "Paris",
  "country": "France", 
  "temperature": 22.5,
  "windspeed": 12.3,
  "weather_code": 200,
  "wind_alert_level": 1,
  "heat_alert_level": 0,
  "location": "Paris, France"
}
```

### **Optimisations**
- **Batch Writing**: RÃ©duction des I/O par Ã©criture groupÃ©e
- **Path Caching**: Cache des chemins pour Ã©viter les crÃ©ations rÃ©pÃ©tÃ©es
- **Memory Management**: Gestion efficace de la mÃ©moire pour gros volumes
- **Error Recovery**: Retry automatique en cas d'erreur

## ğŸ“Š Monitoring et MÃ©triques

### **MÃ©triques CollectÃ©es**
- Nombre de messages traitÃ©s par seconde
- Latence de traitement moyenne
- Taille des batches et frÃ©quence d'Ã©criture
- RÃ©partition gÃ©ographique des donnÃ©es
- Taux d'erreurs et de retry

### **Logs DÃ©taillÃ©s**
```
[2025-09-22 14:30:15] INFO - Connected to Kafka broker
[2025-09-22 14:30:15] INFO - Subscribed to topics: geo_weather_stream
[2025-09-22 14:30:16] INFO - Processed 50 messages, wrote to FR/Paris/
[2025-09-22 14:30:17] INFO - Batch flush: 150 records to 8 locations
[2025-09-22 14:30:18] INFO - Performance: 125.3 msg/sec avg
```

## ğŸ”§ Configuration

### **Variables d'Environnement**
```bash
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_GROUP_ID=hdfs_consumer_group
KAFKA_AUTO_OFFSET_RESET=earliest

# HDFS Configuration  
HDFS_BASE_PATH=./hdfs-data
HDFS_BATCH_SIZE=100
HDFS_FLUSH_INTERVAL=30

# Performance Tuning
CONSUMER_TIMEOUT_MS=5000
MAX_POLL_RECORDS=500
```

### **Fichier de Configuration**
```python
# hdfs_config.py
HDFS_CONFIG = {
    'base_path': './hdfs-data',
    'batch_size': 100,
    'flush_interval': 30,
    'max_file_size': '100MB',
    'compression': 'gzip',
    'replication_factor': 1
}

KAFKA_CONFIG = {
    'bootstrap_servers': 'localhost:9092',
    'group_id': 'hdfs_consumer_group',
    'auto_offset_reset': 'earliest',
    'enable_auto_commit': True,
    'consumer_timeout_ms': 5000
}
```

## ğŸ¯ Cas d'Usage

### **1. Data Lake Weather**
Stockage centralisÃ© de toutes les donnÃ©es mÃ©tÃ©o pour analytics:
```bash
python hdfs_consumer.py --hdfs-path "./weather_lake" --topics "weather_stream,alert_stream"
```

### **2. Real-time Backup**
Sauvegarde en temps rÃ©el des streams critiques:
```bash
python hdfs_consumer.py --hdfs-path "./backup" --topics geo_weather_stream --monitoring
```

### **3. Multi-Region Storage**
RÃ©plication gÃ©ographique des donnÃ©es:
```bash
python hdfs_consumer.py --hdfs-path "./region_eu" --topics geo_weather_stream
python hdfs_consumer.py --hdfs-path "./region_us" --topics geo_weather_stream
```

## ğŸ“ˆ Performance

### **Benchmarks**
- **Throughput**: 1000+ messages/seconde
- **Latency**: < 10ms par message
- **Storage**: Compression 60-70% avec JSONL
- **Memory**: < 100MB pour 1M messages
- **Scalability**: Support multi-consumer groups

### **Optimisations**
```python
# Configuration haute performance
PERFORMANCE_CONFIG = {
    'batch_size': 500,          # Batches plus grands
    'flush_interval': 10,       # Flush plus frÃ©quent
    'buffer_memory': '128MB',   # Buffer mÃ©moire Ã©tendu
    'compression_type': 'gzip', # Compression pour stockage
    'max_poll_records': 1000    # Plus de records par poll
}
```

## ğŸ” Validation

### **Tests de Fonctionnement**
1. **Consumer Basic**: RÃ©ception et stockage des messages
2. **Partitioning**: VÃ©rification de l'organisation gÃ©ographique
3. **Performance**: Tests de charge avec volumes importants
4. **Recovery**: Tests de rÃ©cupÃ©ration aprÃ¨s erreurs
5. **Monitoring**: Validation des mÃ©triques et logs

### **Commandes de Test**
```bash
# Test basic
python test_exercice7.bat

# Test performance
python hdfs_consumer.py --hdfs-path "./test_hdfs" --topics geo_weather_stream --batch-size 1000

# VÃ©rification des donnÃ©es
ls -la hdfs-data/*/*/alerts.json
wc -l hdfs-data/*/*/alerts.json
```

## ğŸš€ IntÃ©gration

### **Avec Exercice 6 (Geo Producer)**
```bash
# Terminal 1: Producer gÃ©ographique
cd ../exercice6
python geo_weather.py Paris France --continuous

# Terminal 2: Consumer HDFS  
cd ../exercice7
python hdfs_consumer.py --hdfs-path "./hdfs-data" --topics geo_weather_stream
```

### **Pipeline Complet**
1. **Exercice 6**: Production de donnÃ©es mÃ©tÃ©o gÃ©olocalisÃ©es
2. **Exercice 7**: Stockage HDFS structurÃ©
3. **Exercice 8**: Visualisation et analytics BI

## ğŸ“š DÃ©pendances

```bash
pip install kafka-python pandas pathlib2
```

## ğŸŠ Validation

Pour valider l'exercice :
1. Lancer le consumer HDFS
2. VÃ©rifier la crÃ©ation de la structure de dossiers
3. Valider le format JSONL des fichiers
4. Tester la performance avec volumes importants
5. VÃ©rifier les mÃ©triques de monitoring

---

**ğŸ¯ Cet exercice dÃ©montre la capacitÃ© Ã  crÃ©er un systÃ¨me de stockage distribuÃ© robuste et performant pour des donnÃ©es de streaming en temps rÃ©el.**